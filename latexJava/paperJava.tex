\documentclass{article}

\usepackage{minted}
\usepackage{hyperref}

\title{Crawler and Inverted Index in Java}

\newcommand{\authorblock}[1]{\begin{tabular}{@{}c@{}}#1\end{tabular}}

\author{\centering\begin{tabular}{ccc}
	\authorblock{
		Aurora Zuoris\\
		\normalsize{aurora.zuoris101@alu.ulgpc.es}
	} &
	\authorblock{
	Alejandra Ruiz de Adana Fleitas\\
	\normalsize{alejandra.ruiz104@alu.ulpgc.es}
	} \\ \\
	\authorblock{
	Lam Truong Nguyen\\
	\normalsize{lam.nguyen101@alu.ulpgc.es}
	} &
	\authorblock{
	Aris Vazdekis Soria\\
	\normalsize{aris.vazdekis101@alu.ulpgc.es}
	} \\ \\
	\authorblock{
	Jaime Ballesteros Domínguez\\
	\normalsize{jaime.ballesteros101@alu.ulpgc.es}
	} &
	\authorblock{
	Anna Barbara Król\\
	\normalsize{anna.krol101@alu.ulpgc.es}
	}
\end{tabular}}

\begin{document}
\maketitle
\abstract{ 
In this project, we undertook the task of transforming code in Java to enhance search efficiency among a wide variety of text documents. The primary challenge we faced was the need to quickly access documents containing specific terms within an extensive library. Our code encompasses three concurrent modules: Crawler, Indexer and QueryEngine, all working in unison to ensure seamless operation. To accomplish this task, we followed these steps: we retrieved and collected digital documents, then processed and indexed these documents for efficient search, and provided a user-friendly interface for searching and retrieving specific documents within the extensive digital library.
%tu dodac co porownujemy i conslusions
}

\section{Introduction}
In today's world there is an ever increasing
number of documents that are being created and stored digitally.
Thus the need to easily find and access these documents becomes
ever more important. This is where the inverted index comes in.
An inverted index is a method of creating indices for a given set of documents that allows for fast searching of the documents based on the words they contain. The 'crawler' module is responsible for retrieving, processing, and storing textual content from books available on the Gutenberg.org website. It ensures that these texts are integrated seamlessly into the inverted index. Furthermore, the 'Query Engine' module enables searching for and retrieving specific books within this extensive digital library. The harmonious synergy of three modules addresses the challenge of efficiently accessing and exploring an ever-expanding collection of digital documents.


\section{Methodology}

Our project follows a systematic approach, divided into three major modules: the Crawler, Inverted Index and Query Engine. First, we employ a data collection program within the Crawler module to download documents from the Gutenberg Project. Then, in the Inverted Index module, we process these documents by tokenization, creating a reverse keyword index. Subsequently, the Query Engine module provides a user-friendly interface for searching and retrieving specific documents. Finally, we store the indexed data in an SQLite database for future querying. 

\subsection{Crawler}

The "Crawler" module consists of a set of interconnected classes, each contributing to the execution of this complex task. This detailed description sheds light on how these classes work together in the process of downloading and handling book content.
The classes mentioned work as follows:
\begin{itemize}
\item
The \texttt{ContentExtractor} class plays a fundamental role in the process by fetching text from specific books hosted on Gutenberg.org. It is capable of extracting textual data from the site using HTTP requests. To initiate the process, it requires a unique book identifier, and upon successful retrieval, it returns the book's text. This class serves as the initial point of contact with the online library.
\item
The \texttt{FileSystemDatalake} class is responsible for the storage and management of the downloaded textual content. It converts the raw book text into JSON format and stores it in files, with each file named after the respective book's identifier. This class plays a crucial role in creating and maintaining the Datalake directory structure, ensuring organized and efficient data storage.
\item
The \texttt{LibroGutenberg} class is pivotal in the process of extracting meaningful information from the downloaded book text. It utilizes regular expressions to search for and identify various attributes, such as the book's title, author, publication date, language, and, most importantly, the book's actual textual content. This class ensures the structured extraction of metadata and book text.
\item
The \texttt{TimerAPI} class provides an interface for configuring essential parameters related to the book retrieval process. It allows for the adjustment of the execution period, which determines how frequently the system fetches new books. Additionally, it enables users to specify the number of books to download per minute and set a maximum limit for the number of books to retrieve. This class is accessible through an HTTP interface, making it a valuable tool for process customization.
\item
The \texttt{Controller} class serves as the orchestrator of the entire process. It initiates a timer that cyclically triggers the execution of operations for downloading and saving book texts. During this continuous process, it leverages the functionality of the \texttt{ContentExtractor}, \texttt{FileSystemDatalake}, and \texttt{LibroGutenberg} classes. By doing so, it ensures that books are fetched, processed, and stored systematically.
\end{itemize}
Finally The main \texttt{Main} class initializes the entire system. It sets the port for the system, initializes the Spark server, and passes the location of the Datalake directory to the \texttt{Controller} class.

\subsection{Indexer}

The Inverted Index module is essential for creating and managing inverted indices based on available textual documents. This module plays a crucial role in information retrieval, text analysis, and natural language processing tasks.

\begin{itemize}
\item
The \texttt{FileDatalake} class represents access to the source of textual data stored as files. 
\begin{itemize}
\item Function \texttt{documents()} returns a set of document identifiers available in the data source.
\item  Function \texttt{readDocument(int document)} reads the text content of a specific document based on its identifier.
\end{itemize}

\item
The \texttt{Indexer} class is responsible for creating an inverted index based on documents stored in the \texttt{FileDatalake} and storing it in the \texttt{Datamart}, with the actual implementation being injected as a dependency on creation. The class provides the following functionalities:

\begin{itemize}
  \item \texttt{tokenize(String document)}: Tokenizes the text content of a document, this is done using a state machine pattern that processes the text character by character, trying to be much more efficient than a regular expression.
		It returns a set of tokens found in the document.
  \item \texttt{index()}: Initiates the indexing process. It creates an inverted index from the available documents in the \texttt{FileDatalake} and stores it in the \texttt{Datamart}.
		After it finishes, it blocks in a loop, listening in on new documents being added to the datalake, and updating the index accordingly as they are added.
\end{itemize}

\item 
The \texttt{IndexerState} enumeration defines the states for the tokenization state machine used by the \texttt{Indexer} class. The states are as follows:

\begin{itemize}
	\item \texttt{OutOfToken} The state machine is not currently processing a token.
	\item \texttt{InToken} The state machine is currently processing a token.
	\item \texttt{InValidTokenUnknownEnd} The state machine is in an ambiguous position, where whenever the current token ends early or continues depends on future characters.
	\item \texttt{InInvalidToken} The state machine is currently processing an invalid token, and thus should ignore future valid characters until the token ends.
		This can for example occur when the token is too long, as no one is going to search for tokens that are many times longer than an average word.
\end{itemize}
\end{itemize}

Finally the \texttt{Main} class serves as the entry point for the program. It accepts two command-line arguments: the path to the \texttt{datalake} (data source) and \texttt{datamart} (destination for the inverted index).
The program creates instances of \texttt{FileDatalake} and an instance the \texttt{Datamart} and then initiates the indexing process using the \texttt{Indexer} class.
Aditionally, this module has various unit tests for ensuring the correctness and robustness of the tokenization implementation,
as this part is the most complex and error-prone in the project, especially considering that it deals with any arbitrary unvetted text coming in from the internet.

\subsection{Query Engine}

The Query Engine module is responsible for providing an API interface and search functionality for indexed documents. This section provides an overview of the key classes and their interactions within the Query Engine module.

\begin{itemize}
\item
The \texttt{Controller} class serves as the controller in the Query Engine module. It is responsible for initializing and running a server that handles client requests. The \texttt{Controller} class invokes the \texttt{startServer} method of the \texttt{SparkWebService} object.

\item
The \texttt{SparkWebService} class utilizes the Spark library to launch an HTTP server. This server listens on a specified port and handles HTTP requests, particularly GET requests. It provides a single main query, \texttt{/v1/search}, allowing users to search for documents based on keywords.

\item
The \texttt{SqliteReader} class is responsible for communication with the SQLite database, which stores information about keyword indexes within documents. When the server receives a request with a keyword, the \texttt{SqliteReader} extracts information about the documents containing that keyword from the database.

\item 
The \texttt{Document} class represents an individual textual document. It includes information such as document ID, date, author, content, title, and language.
\end{itemize}


The \texttt{Main} class contains the \texttt{main} function, which serves as the entry point for the Query Engine module. It primarily initializes a \texttt{Controller} object and starts the API server.


The collaboration among these classes is as follows: The Spark server listens for search requests and, upon receiving a query, forwards it to the \texttt{SqliteReader}. The \texttt{SqliteReader} communicates with the SQLite database to retrieve documents containing the specified keyword. The results are processed and returned to the client in JSON format via the Spark server. This allows users to search for documents based on keywords and receive results efficiently.

\subsection{Datamart}

The Datamart module handles the storage and management of the inverted index. It defines methods for indexing keywords, retrieving documents associated with a keyword, and obtaining a list of all available documents in the index. Two implementations are provided: a SQL-based Datamart using SQLite and a File-based Datamart using file storage.
\begin{itemize}

\item 
The SQL-based Datamart in \texttt{SqlDatamart} module stores the inverted index using a SQL database, associating keywords with document lists.

\item 
The File-based Datamart in \texttt{FileDatamart} module employs file storage to maintain the inverted index, where each keyword corresponds to a file containing document IDs. 
\end{itemize}
The Datamart module provides a reliable solution for the storage and retrieval of the inverted index. The choice between provided implementations depends on project requirements and scale.
File-Based approach is suitable for smaller-scale projects where a full database system might be unnecessary, offering flexibility and efficiency in data storage.

\section{Results and conclusions}

The biggest improvement is the new tokenization algorithm, which is orders of magnitude faster than the old methods used in the project.
Also given that it is implemented by hand, it is much more flexible and can be easily modified to suit the needs of the project.

The code of this project can be found in the following repository: \url{https://github.com/Aurora2500/inverse-index-big-data}

\section{Future work}

In the future, the new file datamart could be improved further to be faster using all sorts of different caching techniques to reduce the number of IO operations.

\end{document}





