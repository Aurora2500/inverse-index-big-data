\documentclass{article}

\usepackage{minted}
\usepackage{hyperref}

\title{Crawler and Inverted Index in Java}

\newcommand{\authorblock}[1]{\begin{tabular}{@{}c@{}}#1\end{tabular}}

\author{\centering\begin{tabular}{ccc}
	\authorblock{
		Aurora Zuoris\\
		\normalsize{aurora.zuoris101@alu.ulgpc.es}
	} &
	\authorblock{
	Alejandra Ruiz de Adana Fleitas\\
	\normalsize{alejandra.ruiz104@alu.ulpgc.es}
	} \\ \\
	\authorblock{
	Lam Truong Nguyen\\
	\normalsize{lam.nguyen101@alu.ulpgc.es}
	} &
	\authorblock{
	Aris Vazdekis Soria\\
	\normalsize{aris.vazdekis101@alu.ulpgc.es}
	} \\ \\
	\authorblock{
	Jaime Ballesteros Domínguez\\
	\normalsize{jaime.ballesteros101@alu.ulpgc.es}
	} &
	\authorblock{
	Anna Barbara Król\\
	\normalsize{anna.krol101@alu.ulpgc.es}
	}
\end{tabular}}

\begin{document}
\maketitle
\abstract{ 
In this project, we undertook the task of transforming code in Java to enhance search efficiency among a wide variety of text documents. The primary challenge we faced was the need to quickly access documents containing specific terms within an extensive library. Our code encompasses three concurrent modules: Crawler, Indexer and QueryEngine, all working in unison to ensure seamless operation. To ensure optimal performance, we integrated a timer mechanism that defaults to downloading 100 books per minute.
%To accomplish this task, we followed these steps:
%we collected a hundred English books, tokenized them to split them into words, built an inverted index that could relate these terms to the specific ID of each book, and developed a series of tables that allowed us to associate both the tokenized words with the IDs and these IDs with the metadata specific to each book.
%tu dodac co porownujemy i co lepsze
}

\section{Introduction}
In today's world there is an ever increasing
number of documents that are being created and stored digitally.
Thus the need to easily find and access these documents becomes
ever more important. This is where the inverted index comes in.
An inverted index is a method of creating indices for a given set of documents that allows for fast searching of the documents based on the words they contain. The 'crawler' module is responsible for retrieving, processing, and storing textual content from books available on the Gutenberg.org website. It systematically downloads and handles book content, ensuring that these texts are integrated seamlessly into the inverted index. 

\section{Methodology}

First, we 

\subsection{Crawler}

The "Crawler" module consists of a set of interconnected classes, each contributing to the execution of this complex task. This detailed description sheds light on how these classes work together in the process of downloading and handling book content.
The classes mentioned work as follows:
\begin{itemize}
\item
The \texttt{ContentExtractor} class plays a fundamental role in the process by fetching text from specific books hosted on Gutenberg.org. It is capable of extracting textual data from the site using HTTP requests. To initiate the process, it requires a unique book identifier, and upon successful retrieval, it returns the book's text. This class serves as the initial point of contact with the online library.
\item
The \texttt{FileSystemDatalake} class is responsible for the storage and management of the downloaded textual content. It converts the raw book text into JSON format and stores it in files, with each file named after the respective book's identifier. This class plays a crucial role in creating and maintaining the Datalake directory structure, ensuring organized and efficient data storage.
\item
The \texttt{LibroGutenberg} class is pivotal in the process of extracting meaningful information from the downloaded book text. It utilizes regular expressions to search for and identify various attributes, such as the book's title, author, publication date, language, and, most importantly, the book's actual textual content. This class ensures the structured extraction of metadata and book text.
\item
The \texttt{TimerAPI} class provides an interface for configuring essential parameters related to the book retrieval process. It allows for the adjustment of the execution period, which determines how frequently the system fetches new books. Additionally, it enables users to specify the number of books to download per minute and set a maximum limit for the number of books to retrieve. This class is accessible through an HTTP interface, making it a valuable tool for process customization.
\item
The \texttt{Controller} class serves as the orchestrator of the entire process. It initiates a timer that cyclically triggers the execution of operations for downloading and saving book texts. During this continuous process, it leverages the functionality of the \texttt{ContentExtractor}, \texttt{FileSystemDatalake}, and \texttt{LibroGutenberg} classes. By doing so, it ensures that books are fetched, processed, and stored systematically.
\end{itemize}
The complete workflow of the "crawler" module can be summarized as follows:

1. Parameters for the download frequency, books per minute, and the maximum number of books to retrieve are configured using the \texttt{TimerAPI} class.

2. The main \texttt{Main} class initializes the entire system. It sets the port for the system, initializes the Spark server, and passes the location of the Datalake directory to the \texttt{Controller} class.

3. The \texttt{Controller} class takes charge of initiating the process of downloading book texts. The process is repetitive and continues until the maximum number of books is reached or other predefined termination criteria are met.

4. The \texttt{ContentExtractor} class is employed to retrieve textual content from specific books, while the \texttt{LibroGutenberg} class handles the subsequent processing of the text, extracting valuable attributes.

5. The \texttt{FileSystemDatalake} class manages the storage of the downloaded text in JSON format. It is responsible for creating a structured directory hierarchy, facilitating efficient data storage.

The "crawler" module serves as a vital component within the system, enabling the retrieval, structured processing, and organized storage of textual content from the Gutenberg.org website. This content can subsequently be accessed and utilized in various ways, making it a versatile and valuable module for data acquisition and management.

\subsection{Indexer}
\subsection{Query Engine}


\section{Results and conclusions}


The code of this project can be found in the following repository: \url{https://github.com/Aurora2500/inverse-index-big-data}

\section{Future work}

There are various ways in which this project could be improved.

\end{document}





